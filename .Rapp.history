save.pkg.list <- installed.packages()[is.na(installed.packages()[ , "Priority"]), 1]
save(save.pkg.list, file="pkglist.Rdata")
load("pkglist.Rdata")#
install.packages(save.pkg.list)
save.pkg.list
typeof(save.pkg.list)
x<-x[-which(x==4)]
save.pkg.list<-save.pkg.list[-which(save.pkg.list=="financial")]
load("pkglist.Rdata")#
install.packages(save.pkg.list)
save.pkg.list<-save.pkg.list[-which(save.pkg.list=="zoo")]
save.pkg.list
save.pkg.list<-save.pkg.list[-which(save.pkg.list=="financial")]
save.pkg.list
load("pkglist.Rdata")#
install.packages(save.pkg.list)
save.pkg.list<-save.pkg.list[-which(save.pkg.list=="financial")]
install.packages(save.pkg.list)
Sys.getenv("PATH")
load("pkglist.Rdata")
save.pkg.list<-save.pkg.list[-which(save.pkg.list=="financial")]
install.packages(save.pkg.list)
library(party)#
library(rpart)#
library(ggplot2)#
library(randomForest)
head(kyphosis)
summary(kyphosis)
length(kyphosis)
require(devtools)
install_github("slidify", "ramnathv")
For data manipulation and visualization#
library(party)#
library(rpart)#
library(caret)#
#
# Replace the path here with the appropriate one for your machine#
myprojectpath = "/Users/eoinbrazil/Desktop/DublinR/TreesAndForests/DublinR-ML-treesandforests/"#
#
# Set the working directory to the current location for the project files#
setwd(myprojectpath)#
#
# Replace the path here with the appropriate one for your machine#
scriptpath = paste(myprojectpath, "scripts/", sep="")#
datapath = paste(myprojectpath, "data/", sep="")#
graphpath = paste(myprojectpath, "graphs/", sep="")#
#
# Load the Car dataset into a dataframe for processing#
car.df = read.csv(paste(datapath, "car.csv", sep=""))#
#
# Explore the first ten records of the dataset to take a peek#
head(car.df)#
#
# Look to get a summary of the dataset for each variable in the dataframe#
summary(car.df)#
#
# The key variable we are interested in deteriming is claim or 'clm' with 0 = no claim and 1 = a claim#
# Determine what the other variables are from the carDataSetDescription.txt file to see which are potential predictors#
predictors.to.clm.var = clm ~ veh_value + veh_body + veh_age + gender + area + agecat#
#
# A quick single tree using the full dataset to see what are the potential splits#
SingleTree = ctree(predictors.to.clm.var, data = car.df)#
plot(SingleTree, type="simple")
inTrainIndexes <- createDataPartition(y = car.df$clm, p=.8, list = FALSE)#
car.df.train = car.df[inTrainIndexes,]#
car.df.test = car.df[-inTrainIndexes,]#
#
ClaimModel.ctree <- ctree(predictors.to.clm.var, data=car.df.train)#
plot(ClaimModel.ctree, type="simple")#
summary(ClaimModel.ctree)
ClaimModel.ctree
car.df.train$clm
confusionMatrix(claimPred <- predict(ClaimModel.ctree, car.df.test)#
confusionMatrix(claimPred, car.df.test$clm, positive=1), testing$Class, positive='WS')
claimPred <- predict(ClaimModel.ctree, car.df.test)#
confusionMatrix(claimPred, car.df.test$clm, positive=1)
claimPred <- predict(ClaimModel.ctree, car.df.test)#
confusionMatrix(claimPred, car.df.test$clm, positive='1')
claimPred <- predict(ClaimModel.ctree, car.df.test)#
claimPred
confusionMatrix(claimPred, car.df.test$clm)
library(ROCR)
confusionMatrix(claimPred, car.df.test$clm)
car.df.test$clm
factors(car.df.test$clm)
factor(car.df.test$clm)
factor(car.df.train$clm)
claimPred <- predict(ClaimModel.ctree, newdata=car.df.test)
confusionMatrix(claimPred, car.df.test$clm)
claimProbs <- treeresponse(ClaimModel.ctree, newdata=car.df.test)
claimPred <- do.call(rbind, claimPred)
claimPred <- predict(ClaimModel.ctree, newdata=car.df.test)
claimPred <- do.call(rbind, claimPred)
roc_pred <- prediction(claimPred[,1], car.df.test$clm)#
plot(performance(roc_pred, measure="tpr", x.measure="fpr"), colorize=TRUE)
plot(performance(roc_pred, measure="lift", x.measure="rpp"), colorize=TRUE)
claims.pred <- prediction(claimPred[,1], car.df.test$clm)#
plot(performance(claims.pred, measure="tpr", x.measure="fpr"), colorize=TRUE)#
plot(performance(claims.pred, measure="lift", x.measure="rpp"), colorize=TRUE)#
plot(performance(claims.pred, measure="sens", x.measure="spec"), colorize=TRUE)
confusionMatrix(claimPred[,1], car.df.test$clm)
confusionMatrix(claims.pred, car.df.test$clm)
claims.pred
confusionMatrix(claims.pred$predictions, car.df.test$clm)
confusionMatrix(claims.pred$predictions, car.df.test$clm)
unique(claims.pred$predictions)
unique(claims.pred[,1]
)
length(claims.pred[,1])
as.vector(claims.pred[,1])
claimPred <- predict(ClaimModel.ctree, newdata=car.df.test)
claimPred
length(claimPred)
levels(claimPred)
level(claimProbs)
levels(claimProbs)
unique(claimProbs)
claimProbs
claimProbs#
confusionMatrix(claimProbs, car.df.test$clm)
confusionMatrix(claimProbs, car.df.test$clm)
ClaimModel.ctree <- ctree(predictors.to.clm.var, data=car.df.train)#
plot(ClaimModel.ctree, type="simple")#
summary(ClaimModel.ctree)
table(predict(ClaimModel.ctree), iris$Species)table(claimPred, car.df.test$clm)
table(claimPred, car.df.test$clm)
irisct <- ctree(Species ~ .,data = iris)#
    irisct#
    plot(irisct)#
    table(predict(irisct), iris$Species)
irisct
table(predict(ClaimModel.ctree, newdata=car.df.test), car.df.test$clm)
plot(performance(claimPred, measure="tpr", x.measure="fpr"), colorize=TRUE)
library(AppliedPredictiveModeling)#
library(caret)#
library(doMC)#
library(pROC)#
library(rpart.plot)	# Fancy tree plot#
library(rattle) # Nice tree plot from rattle - fancyRpartPlot#
library(RColorBrewer)
data(segmentationData)#
#
# Remove the Cell identification data#
segmentationData$Cell <- NULL#
#
# The dataset already has defined training and test subsets, no need to subset#
training <- subset(segmentationData, Case == "Train")#
testing <- subset(segmentationData, Case == "Test")#
# Remove the Case identification data#
training$Case <- NULL#
testing$Case <- NULL#
str(training[,1:6])#
#
# Use three repeats of 10–fold cross–validation to train the tree#
# 10-fold CV can be noisy/over-fitted for small to moderate sample sizes but we'll risk it for higher performances#
# The CART algorithm uses overall accuracy and the one standard–error rule to prune the tree, however we can also choose the tree complexity based on the largest absolute area under the ROC curve.#
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3, summaryFunction = twoClassSummary, classProbs = TRUE)#
rpartTune <- train(Class ~ ., data = training, method = "rpart", tuneLength = 30, metric = "ROC", trControl = cvCtrl)#
#
# Plot the#
plot(rpartTune, scales = list(x = list(log = 10)))
head(training)
head(training[,1:2])
head(training[,1])
head(training[1:2,])
table(training$class)
table(training.class)
table(training[,1])
table(testing[,1])
